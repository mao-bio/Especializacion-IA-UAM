{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Actividad 3: Construcción de algoritmos de clasificación para análisis de sentimientos y reconocimiento de entidades.\n",
        "\n",
        "**Introducción**\n",
        "\n",
        "Esta actividad consiste en construir dos herramientas de procesamiento de lenguaje natural (PLN):\n",
        "\n",
        "1.  **Analizador de Sentimiento:** Determina si un texto expresa un sentimiento positivo, negativo o neutral.\n",
        "2.  **Etiquetador POS (Part-of-Speech):** Asigna a cada palabra de un texto su categoría gramatical (sustantivo, verbo, adjetivo, etc.).\n",
        "\n",
        "Se utilizarán las siguientes librerías:\n",
        "\n",
        "*   **TextBlob:** Para el análisis de sentimiento (una capa sobre NLTK que simplifica esta tarea).\n",
        "*   **spaCy:** Para el POS tagging (una librería moderna y eficiente para PLN).\n",
        "*   **NLTK:** Para el preprocesamiento de texto.\n",
        "\n",
        "**Objetivos del Ejercicio**\n",
        "\n",
        "1.  **Comprender Conceptos Clave:**\n",
        "    *   Análisis de sentimiento (polaridad).\n",
        "    *   POS tagging.\n",
        "    *   Preprocesamiento de texto.\n",
        "    *   Pruebas unitarias.\n",
        "\n",
        "2.  **Desarrollar Habilidades de Programación:**\n",
        "    *   Trabajar con librerías de PLN en Python (TextBlob, spaCy, NLTK).\n",
        "    *   Implementar funciones de análisis de texto.\n",
        "    *   Ejecutar pruebas unitarias.\n",
        "    *   Trabajar colaborativamente.\n",
        "\n",
        "3.  **Construir Herramientas Útiles:**\n",
        "    *   Crear un sistema que pueda analizar el sentimiento de un texto.\n",
        "    *   Crear un sistema que pueda etiquetar las palabras de un texto según su función gramatical.\n",
        "\n",
        "\n",
        "## 1. Ejecute la siguiente celda para cargar las librerias nesesarias y descargar los complementos"
      ],
      "metadata": {
        "id": "sWHGhjLD_qlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "from collections import Counter\n",
        "import re\n",
        "import unittest\n",
        "\n",
        "# Descarga de recursos de NLTK y Spacy\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "    nltk.data.find('corpora/omw-1.4')\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "    nltk.data.find('averaged_perceptron_tagger') # Para POS Tagging\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')\n",
        "    nltk.download('omw-1.4')\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('punkt')\n",
        "    nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    print(\"Downloading en_core_web_sm model...\")\n",
        "    !python -m spacy download en_core_web_sm\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "-PZlCpQWNsEV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a1633db-dfff-4e4f-bf65-c7a601b48096"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm  #En consola, fuera del notebook"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KApriw1DI_w1",
        "outputId": "9ee27195-d826-4a8b-9e55-5c5f6161a345"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Ejecute la siguiente definiendo los parametros restantes\n",
        "\n",
        "\n",
        "\n",
        "*   **`umbral_polaridad_positiva`**: Este parámetro define el umbral de polaridad por encima del cual un texto se considerará \"positivo\". La polaridad es un valor numérico que va de -1 (muy negativo) a +1 (muy positivo), donde 0 indica neutralidad.\n",
        "*   **`umbral_polaridad_negativa`**: Define el umbral de polaridad por debajo del cual un texto se considerará \"negativo\".\n",
        "*   **`frecuencia_minima`**: Este parámetro se usa en la función pos_tagging. Determina la frecuencia mínima que debe tener una palabra en el texto para que se le asigne una etiqueta POS (Part-of-Speech). Si una palabra aparece menos veces que este valor, no se incluirá en el resultado del etiquetado POS (Este valor dejenlo en 1 para que evalue todas las palabras de la oración).\n",
        "\n"
      ],
      "metadata": {
        "id": "5jg5w2o9Tr60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuración (Parámetros) ---\n",
        "#@markdown ### **Configuración de Parámetros**\n",
        "\n",
        "#@markdown **Opciones de Análisis de Sentimiento:**\n",
        "umbral_polaridad_positiva = 0.1  #@param {type:\"number\"}\n",
        "umbral_polaridad_negativa = -0.1 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown **Opciones de Análisis de Texto (para POS Tagging):**\n",
        "frecuencia_minima = 1  #@param {type:\"integer\"}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JOFD-XxCTsUE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Realice el codigo de las siguientes funciones y ejecute esa celda y la de las pruebas unitarias para comprobar su validez.\n",
        "\n",
        "A continuación, se describen las funciones que debes implementar.  Para cada función, se proporciona:\n",
        "\n",
        "*   **Nombre de la función y parámetros:**  Incluye los tipos de datos esperados.\n",
        "*   **Docstring:** Una descripción detallada del propósito de la función, sus argumentos y el valor de retorno esperado.  *Lee esto con atención*.\n",
        "*   **Esqueleto de la función:** El código básico de la función, con un `pass` donde debes escribir tu implementación.\n",
        "* **Pruebas unitarias:** Recuerda que cada funcion cuenta con una prueba unitaria para probar que tu codigo funcione correctamente.\n",
        "\n",
        "**Importante:**\n",
        "\n",
        "*   **No modifiques los nombres de las funciones ni los parámetros.**  Las pruebas unitarias dependen de ellos.\n",
        "*   **Lee cuidadosamente los docstrings.**  Contienen información esencial.\n",
        "*   **Reemplaza el `pass` con tu código.**\n",
        "*   **Ejecuta las pruebas unitarias después de implementar cada función.**\n",
        "\n",
        "**Ejemplo:**\n",
        "\n",
        "```\n",
        "def Nombre de la funcion(parametros):\n",
        "    \"\"\"\n",
        "    Docstring\n",
        "\n",
        "    Args:\n",
        "        Entradas.\n",
        "\n",
        "    Returns:\n",
        "        salidas (return ...) .\n",
        "    \"\"\"\n",
        "    # --- IMPLEMENTAR AQUÍ ---\n",
        "    pass\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "qlwqfxye_qlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment(text):\n",
        "    \"\"\"\n",
        "    Analiza el sentimiento de un texto usando TextBlob.\n",
        "\n",
        "    Args:\n",
        "        text (str): El texto a analizar.\n",
        "\n",
        "    Returns:\n",
        "        str:  \"positive\", \"negative\", o \"neutral\", según la polaridad del texto.\n",
        "    \"\"\"\n",
        "    analysis = TextBlob(text)\n",
        "    polarity = analysis.sentiment.polarity\n",
        "\n",
        "    if polarity > umbral_polaridad_positiva:\n",
        "        return \"positive\"\n",
        "    elif polarity < umbral_polaridad_negativa:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "def pos_tagging(text):\n",
        "    \"\"\"\n",
        "    Realiza POS tagging usando Spacy, filtrando por frecuencia mínima.\n",
        "\n",
        "    Args:\n",
        "        text (str): El texto a analizar.\n",
        "\n",
        "    Returns:\n",
        "        dict: Un diccionario donde las claves son las palabras (que cumplen la\n",
        "              frecuencia mínima) y los valores son sus POS tags.\n",
        "              Si no hay palabras, devuelve un diccionario vacío.\n",
        "    \"\"\"\n",
        "    doc = nlp(text)\n",
        "    words = [token.text for token in doc]\n",
        "    freq = Counter(words)\n",
        "\n",
        "    pos_tags = {}\n",
        "    for token in doc:\n",
        "        if freq[token.text] >= frecuencia_minima:\n",
        "            pos_tags[token.text.lower()] = token.pos_\n",
        "\n",
        "    return pos_tags\n"
      ],
      "metadata": {
        "id": "P6VolMzsmwjs"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### **Pruebas Unitarias**\n",
        "\n",
        "# --- Pruebas Unitarias ---\n",
        "class TestFunctions(unittest.TestCase):\n",
        "\n",
        "    def test_analyze_sentiment(self):\n",
        "        test_cases = [\n",
        "            (\"This is a great movie!\", \"positive\"),\n",
        "            (\"I hate this product.\", \"negative\"),\n",
        "            (\"The weather is okay.\", \"positive\"),\n",
        "            (\"\", \"neutral\"),  # Caso de texto vacío\n",
        "            (\"This is absolutely amazing!!!\", \"positive\"),\n",
        "            (\"This is absolutely terrible!!!\", \"negative\"),\n",
        "            (\"This movie is neither good nor bad.\", \"neutral\")\n",
        "        ]\n",
        "        for text, expected in test_cases:\n",
        "            with self.subTest(text=text):\n",
        "                result = analyze_sentiment(text)\n",
        "                self.assertEqual(result, expected)\n",
        "\n",
        "    def test_pos_tagging(self):\n",
        "        test_cases = [\n",
        "            (\"The quick brown fox jumps over the lazy dog.\",\n",
        "             {'the': 'DET','quick': 'ADJ','brown': 'ADJ', 'fox': 'NOUN', 'jumps': 'VERB', 'over': 'ADP', 'lazy': 'ADJ','dog': 'NOUN','.': 'PUNCT'}),  #Caso simple\n",
        "            (\"I love pizza.\", {'i': 'PRON', 'love': 'VERB', 'pizza': 'NOUN', '.': 'PUNCT'}), #Ninguna palabra con frecuencia minima.\n",
        "            (\"apple apple apple\", {\"apple\":\"NOUN\"}), #Caso con una sola palabra.\n",
        "            (\"\", {}),  # Caso de texto vacío\n",
        "            (\"This is a sentence.  This is another sentence.\",\n",
        "             {'this': 'PRON','is': 'AUX', 'a': 'DET', 'sentence': 'NOUN', '.': 'PUNCT', ' ': 'SPACE', 'another': 'DET'}) #Caso con puntuacion.\n",
        "        ]\n",
        "        for text, expected in test_cases:\n",
        "            with self.subTest(text=text):\n",
        "                result = pos_tagging(text)\n",
        "                self.assertEqual(result, expected)\n",
        "\n",
        "\n",
        "# --- Ejecutar pruebas unitarias y luego la función principal si las pruebas pasan ---\n",
        "if __name__ == '__main__':\n",
        "    suite = unittest.TestLoader().loadTestsFromTestCase(TestFunctions)\n",
        "    result = unittest.TextTestRunner().run(suite)\n",
        "    if result.wasSuccessful():\n",
        "        print(\"\\n--- Todas las pruebas pasaron. Ejecutando la función principal... ---\\n\")\n",
        "    else:\n",
        "        print(\"\\n--- Algunas pruebas fallaron. No se ejecutará la función principal. ---\\n\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YXOASTnCVEW0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcfab541-2532-4261-a528-d01c8c4357de"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "..\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 0.038s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Todas las pruebas pasaron. Ejecutando la función principal... ---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Realice algunas pruebas del codigo final con diferentes textos.\n"
      ],
      "metadata": {
        "id": "8ViKR6pTZxp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Prueba con texto\n",
        "\n",
        "# --- Función Principal (para Colab) ---\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocesa el texto: tokeniza, convierte a minúsculas, elimina\n",
        "    signos de puntuación, caracteres no alfanuméricos y stop words.\n",
        "\n",
        "    Args:\n",
        "        text (str): El texto a preprocesar.\n",
        "\n",
        "    Returns:\n",
        "        list: Una lista de palabras preprocesadas.\n",
        "    \"\"\"\n",
        "    stop_words = set(stopwords.words('english'))  # Usar 'english' o el idioma apropiado\n",
        "    words = word_tokenize(text)\n",
        "    words = [word.lower() for word in words]\n",
        "    # Eliminar puntuación y caracteres no alfanuméricos con expresiones regulares\n",
        "    words = [re.sub(r'[^a-zA-Z0-9\\s]', '', word) for word in words]\n",
        "    words = [word for word in words if word.isalnum()]  # Mantener solo alfanuméricos\n",
        "    words = [word for word in words if word not in stop_words and word != '']\n",
        "    return words\n",
        "\n",
        "def main():\n",
        "    #@markdown ### **Texto de Entrada**\n",
        "    texto_entrada = \"I really enjoy learning new things, but sometimes it can be frustrating when I don't understand a topic right away.\" #@param {type:\"string\"}\n",
        "\n",
        "    if texto_entrada == \"\":\n",
        "        texto_entrada = \"This is a great and amazing movie! I really love it. But, this other movie is terrible and awful.\"\n",
        "\n",
        "    print(\"--- Análisis de Sentimiento ---\")\n",
        "    sentimiento = analyze_sentiment(texto_entrada)\n",
        "    print(f\"Sentimiento general del texto: {sentimiento}\")\n",
        "\n",
        "    print(f\"\\n--- POS Tagging (palabras con frecuencia mínima de {frecuencia_minima}) ---\")\n",
        "    pos_tags = pos_tagging(texto_entrada)\n",
        "    if pos_tags:\n",
        "        for word, tag in pos_tags.items():\n",
        "            print(f\"  '{word}': {tag}\")\n",
        "    else:\n",
        "        print(\"No se encontraron palabras que cumplan la frecuencia mínima.\")\n",
        "\n",
        "# --- Ejecutar la función principal ---\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "JvIxh_oPJOEI",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac2e3191-31f6-4927-ea59-b2b03f2e32c7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Análisis de Sentimiento ---\n",
            "Sentimiento general del texto: positive\n",
            "\n",
            "--- POS Tagging (palabras con frecuencia mínima de 1) ---\n",
            "  'i': PRON\n",
            "  'really': ADV\n",
            "  'enjoy': VERB\n",
            "  'learning': VERB\n",
            "  'new': ADJ\n",
            "  'things': NOUN\n",
            "  ',': PUNCT\n",
            "  'but': CCONJ\n",
            "  'sometimes': ADV\n",
            "  'it': PRON\n",
            "  'can': AUX\n",
            "  'be': AUX\n",
            "  'frustrating': ADJ\n",
            "  'when': SCONJ\n",
            "  'do': AUX\n",
            "  'n't': PART\n",
            "  'understand': VERB\n",
            "  'a': DET\n",
            "  'topic': NOUN\n",
            "  'right': ADV\n",
            "  'away': ADV\n",
            "  '.': PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#positivo\n",
        "print(analyze_sentiment(\"I absolutely loved the new book. It was inspiring and beautifully written!\"))\n",
        "\n",
        "#negativo\n",
        "print(analyze_sentiment(\"The service at the restaurant was terrible and the food was cold.\"))\n",
        "\n",
        "#neutro\n",
        "print(analyze_sentiment(\"The report was submitted on Monday and reviewed on Wednesday.\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjt5WE2fBpCx",
        "outputId": "506aaa8f-ab33-48ac-8c34-76f82df9337b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n",
            "negative\n",
            "neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"They can fish, but the can smells bad\"\n",
        "print(pos_tagging(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4OcHS1T4nRs",
        "outputId": "5ac49e20-e91b-4a9b-928c-db9fb3b9047c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'they': 'PRON', 'can': 'AUX', 'fish': 'VERB', ',': 'PUNCT', 'but': 'CCONJ', 'the': 'PRON', 'smells': 'VERB', 'bad': 'ADJ'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The record was broken, so they will record a new version tomorrow.\"\n",
        "print(pos_tagging(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHxw1sqSBqw0",
        "outputId": "ea2ce389-325f-44be-d9a9-04cc09581002"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 'DET', 'record': 'VERB', 'was': 'AUX', 'broken': 'VERB', ',': 'PUNCT', 'so': 'SCONJ', 'they': 'PRON', 'will': 'AUX', 'a': 'DET', 'new': 'ADJ', 'version': 'NOUN', 'tomorrow': 'NOUN', '.': 'PUNCT'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Suddenly, the quick brown fox jumps over the lazy dog and barks loudly as it runs through the forest.\"\n",
        "print(pos_tagging(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25KiGmtiBuZ5",
        "outputId": "6b1fc0f5-515e-40b2-bb17-a39b45c47de8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'suddenly': 'ADV', ',': 'PUNCT', 'the': 'DET', 'quick': 'ADJ', 'brown': 'ADJ', 'fox': 'NOUN', 'jumps': 'VERB', 'over': 'ADP', 'lazy': 'ADJ', 'dog': 'NOUN', 'and': 'CCONJ', 'barks': 'VERB', 'loudly': 'ADV', 'as': 'SCONJ', 'it': 'PRON', 'runs': 'VERB', 'through': 'ADP', 'forest': 'NOUN', '.': 'PUNCT'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusión:**\n",
        "\n",
        "El análisis de sentimiento y el etiquetado gramatical son herramientas esenciales en el procesamiento del lenguaje natural, ya que a través del análisis de sentimiento, es posible clasificar opiniones o emociones expresadas en un texto, lo cual es útil en áreas como atención al cliente, redes sociales o análisis de productos y por otro lado, el POS tagging permite identificar la función gramatical de cada palabra, lo que facilita tareas como la traducción automática, el resumen de textos o la extracción de información. Esta actividad permitió evidenciar cómo una misma palabra puede tener distintos roles dependiendo del contexto, y cómo la diversidad de categorías gramaticales enriquece la interpretación del lenguaje.\n",
        "\n",
        "Estas técnicas, implementadas correctamente, permiten a las máquinas comprender y manipular el lenguaje humano con mayor precisión y contexto."
      ],
      "metadata": {
        "id": "3IbVkJUFBx7T"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}